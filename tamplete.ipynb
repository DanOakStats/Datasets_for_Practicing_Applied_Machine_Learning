{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOME Dataset\n",
    "\n",
    "\n",
    "BREVE DESCRICAO DO PROBLEMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-bright')\n",
    "import matplotlib.colors\n",
    "from matplotlib import rcParams\n",
    "labelsize = 14\n",
    "rcParams['xtick.labelsize'] = labelsize\n",
    "rcParams['ytick.labelsize'] = labelsize \n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "# machine learning...\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, cohen_kappa_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import recall_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções\n",
    "Vamos criar algumas funções que irão otimizar nosso trabalho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação dos modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_models(X, y, model, metric='accuracy'):\n",
    "    \"\"\"\n",
    "    Função para avaliar os modelos\n",
    "    --------------------------------------------------------------\n",
    "    Parametros:\n",
    "    X = valores de entrada (input values)\n",
    "    y = variável alvo (target value)\n",
    "    model = modelo que sera avaliado\n",
    "    metric = metrica de desempenho. Por padrão \"accuracy\". Obs: para classes desbalanceadas não é melhor metrica de avaliação.\n",
    "    consultar link para ver outras opções : https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    --------------------------------------------------------------\n",
    "    Retorna:\n",
    "    Pontuação (score) do modelo avaliado\n",
    "    \n",
    "    \"\"\"\n",
    "    # definindo nosso KFold Cross-Validation.\n",
    "    kf = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # avaliando com cross_val_score\n",
    "    scores = cross_val_score(model, X, y, scoring=metric, cv=kf, n_jobs=-1)\n",
    "    # retornando pontuação\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(models=dict()):\n",
    "    \"\"\"\n",
    "    Retorna um dicionário de nomes de modelos mapeados para o objeto de modelo scikit-learn\n",
    "    \"\"\"\n",
    "    # MODELOS LINEARES\n",
    "    models['log'] = LogisticRegression()\n",
    "    alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    for a in alphas:\n",
    "        models['ridge-'+str(a)] = RidgeClassifier(alpha=a)\n",
    "    models['pac'] = PassiveAggressiveClassifier(max_iter=1000, tol=1e-3)\n",
    "    models['sgd'] = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "    models['lda'] = LinearDiscriminantAnalysis()\n",
    "    \n",
    "    # MODELOS NAO LINEARES\n",
    "    for k in range(1, 21):\n",
    "        models['knn-'+str(k)] = KNeighborsClassifier(n_neighbors=k)\n",
    "    models['cart'] = DecisionTreeClassifier()\n",
    "    models['extra'] = ExtraTreeClassifier()\n",
    "    models['svml'] = SVC(kernel='linear')\n",
    "    models['svmp'] = SVC(kernel='poly')\n",
    "    c_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    for c in c_values:\n",
    "        models['svmr-'+str(c)] = SVC(C=c)\n",
    "    models['nb'] = GaussianNB()\n",
    "    \n",
    "    # MODELOS ENSEMBLE\n",
    "    models['ada'] = AdaBoostClassifier(n_estimators=100)\n",
    "    models['rf'] = RandomForestClassifier(n_estimators=100)\n",
    "    models['gb'] = GradientBoostingClassifier(n_estimators=100)\n",
    "    models['xgb'] = XGBClassifier()\n",
    "    models['lgb'] = LGBMClassifier(n_estimators=100)\n",
    "    \n",
    "    print(f\"Foram definidos {len(models)} modelos:\")\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apresentação dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(resultados, maximize=True, top_n=10):\n",
    "    \"\"\"\n",
    "     Seleciona os melhores modelos e os apresenta em forma de ranking do melhor para o pior.\n",
    "    resultados = dict contendo nome do modelo atrelado ao seu score\n",
    "    maximize = por padrao True.\n",
    "    top_n = Indica quantos modelo apresentar. Por padrão 10\n",
    "    \"\"\"\n",
    "    meanScores = [(k, v.mean()) for k, v in resultados.items()] # gerando a tupla com (nome, media(pontuação))\n",
    "    meanScores = sorted(meanScores, key=lambda x: x[1]) # ordenando do menor para o maior\n",
    "    if maximize:\n",
    "        meanScores = list(reversed(meanScores)) # faz a reversão do resultado (maior pra menor)\n",
    "    nomes = [x[0] for x in meanScores[:top_n]] # pegando os nomes dos melhores resultados\n",
    "    scores = [resultados[x[0]] for x in meanScores[:top_n]] # armazenando as pontuaçães\n",
    "    # criando o loop para apresentar os resultados\n",
    "    for i in range(top_n):\n",
    "        nome = nomes[i]\n",
    "        meanScore, stdScore = resultados[nome].mean(), resultados[nome].std()\n",
    "        print(f\"Pos:{i+1}, Model:{nome}, Score:{round(meanScore, 4)} ({round(stdScore, 4)})\")\n",
    "        \n",
    "    # plotar o resultados\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.boxplot(scores, showmeans=True)\n",
    "    ax.set_title(\"Melhores Resultados\", fontsize=17)\n",
    "    ax.set_xticklabels(labels=nomes, rotation=15)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANDO OS DADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCRICAO DE ONDE OS DADOS VIERAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando as primeiras entradas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os nomes das nossas features são os seguintes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Começando pelo Básico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual o tamanho do conjunto de dados?\n",
    "A primeira coisa que faremos após importar o dataset será examinar as dimensões do DataFrame e as primeiras entradas. Isso possibilitará criar uma consciência situacional inicial a respeito do formato de entrada e da estrutura geral dos dados.\n",
    "\n",
    "Em relação à dimensionalidade dos dados, nosso conjunto de dados é composto por 1372 observações(entradas) sendo 4 variáveis de entrada e 1 variável de saída (variável alvo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# size of dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quais são os tipos de dados das minhas features?\n",
    "Vamos realizar o levantamento dos tipos de variáveis que compõem o DataFrame a fim de estabelecer a divisão entre as variáveis numéricas e as variáveis categóricas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types of my features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Valores Ausentes\n",
    "Um passo importante na análise de dados é verificação de dados ausentes, isso porque a qualidade de um conjunto de dados está diretamente relacionada à quantidade de valores ausentes. É importante entender logo no início se esses valores nulos são significativos comparados ao total de entradas. Caso eles sejam significativos será necessário um tratamento nos dados antes de realizarmos nossas análises "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumo estatístico\n",
    "O método `pd.describe()` nos ajuda a visualizar as propriedades estatísticas de variáveis numéricas. Exclui variáveis de caracteres.\n",
    "\n",
    "Imediatamente você obtém um resumo contendo algumas das principais informações estatísticas relevantes:\n",
    "\n",
    "* **count** - quantidade de entradas válidas\n",
    "* **mean** - média dos valores\n",
    "* **std** - desvio padrão\n",
    "* **min** - menor valor da coluna\n",
    "* **25%** - (Q1) primeiro quartil 25\n",
    "* **50%** - mediana\n",
    "* **75%** - (Q3) terceiro quartil 75\n",
    "* **max** - maior valor da coluna\n",
    "\n",
    "Com método `pd.describe()` é possível identificar colunas com possíveis outliers (por exemplo, olhando o valor da mediana e comparando com valores máximos e mínimos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusões:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograma\n",
    "Uma maneira rápida de ter uma ideia da distribuição de cada atributo é observar os histogramas. Os histogramas agrupam dados em posições e fornecem uma contagem do número de observações em cada posição. A partir da forma das caixas você pode ter uma ideia rápida de se um atributo é gaussiano, inclinado ou mesmo se tem uma distribuição exponencial. Isso é importante porque muitos algoritmos de aprendizagem de máquinas têm melhor desempenho quando a distribuição das variáveis é gaussiana. Portanto, saber de antemão como está nossa distribuição vai nos ajudar a escolher técnicas de escalonamento mais apropriada para nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusao\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box plot  \n",
    "Um gráfico de caixa é um método para representar graficamente grupos de dados numéricos através de seus quartis. A caixa se estende dos valores do quartil Q1 a Q3 dos dados, com uma linha na mediana (Q2). Os bigodes se estendem desde as bordas da caixa para mostrar o intervalo dos dados. A posição dos bigodes é definido por padrão como `[1.5 * IQR (IQR = Q3 – Q1)]` nas bordas da caixa. Pontos extremos (*outliers*) são aqueles que passaram do fim dos bigodes e identificá-los é importante porque eles podem distorcer uma distribuição de probabilidade e dificultar o dimensionamento de dados usando a padronização (ex. *StandartScaler()*, *MinMaxScaler()*), pois a média e o desvio padrão calculados serão distorcidos pela presença dos mesmos.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=700 src=\"https://miro.medium.com/max/1218/1*r41SQj0LbdCV6rWoIos6mA.png\">\n",
    "</p>   \n",
    "\n",
    "Vamos à visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusões:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de dispersão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico de dispersão mostra o relacionamento entre duas variáveis como pontos em duas dimensões, um eixo para cada atributo. São úteis para identificar relacionamentos estruturados entre variáveis. O *sns.pairplot()* que usaremos para gerar nosso gráfico de dispersão ainda permite passar o parâmetro *hue=* que adiciona uma terceira dimensão onde podemos definir como sendo nossa classe e assim conseguimos ver como está sua distribuição de forma colorida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise da variálvel alvo\n",
    "Nosso objetivo é verificar como está o balanceamento da nossa variável alvo no conjunto de dados. Isso porque dados desequilibrados é algo comum e a maioria dos conjuntos de dados de classificação não possui um número exatamente igual de instâncias em cada classe, mas uma pequena diferença geralmente não importa. Já em problemas onde temos classes altamente desequilibradas algumas estratégias podem ser adotadas, como:\n",
    "* **Coletar mais dados**(Caso possível): Um conjunto de dados maior pode expor uma perspectiva diferente e talvez mais equilibra sobre as classes\n",
    "* **Mudar a métrica de avaliação**: Acurácia(*Accuracy*) não é a métrica a ser usada ao trabalhar com um conjunto de dados desequilibrados. Existem métricas que foram projetadas para contar uma história mais verdadeira ao trabalhar com classes desequilibradas:\n",
    "    \n",
    "    >* Matriz de Confusão;\n",
    "    >* Precisão;\n",
    "    >* Recall;\n",
    "    >* pontuação f1;\n",
    "    >* Kappa de cohen;\n",
    "    >* Curva ROC.    \n",
    "* **Alterar o conjunto de dados**: Utilizar métodos como *Oversampling* e *Undersampling*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir os dados Treino/Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Referência(*Baseline*)\n",
    "O DummyClassifier nos permite criar um modelo muito simples que podemos usar como referência para comparar com outros modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar modelo de referencia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso modelo de referência atingiu uma acurácia de ~54%. Vamos agora avaliar os modelos definidos e ver se conseguimos resultados melhores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliando Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apresentar Resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação dos Dados\n",
    "Muitos algoritmos de *machine learning* têm um melhor desempenho quando as variáveis numéricas de entrada são escaladas para um intervalo padronizado. Isto inclui algoritmos que utilizam uma soma ponderada, como a regressão linear, e algoritmos que utilizam medidas de distância, como os vizinhos k-nearest. \n",
    "\n",
    "Entretanto, é difícil saber se o redimensionamento dos seus dados melhorará o desempenho dos seus algoritmos antes de os aplicar. Muitas vezes pode, mas nem sempre. Uma boa dica é testar vários transformadores e compará-los isto pode rapidamente realçar os benefícios (ou falta deles) de redimensionar os seus dados com determinados modelos, e qual o método de redimensionamento que pode ser digno de mais investigação.\n",
    "\n",
    "Vamos criar funções onde utilizaremos o pacote `sklearn.prepocessing` que vai conter os transformadores e o pacote `sklearn.pipeline` que vai aplicar os transformadores definidos aos nossos modelos. O objetivo do pipeline é encapsular todo o processo logo, fica muito mais fácil validá-lo de forma correta e confiável evitando possíveis erros e vazamento dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Final\n",
    "Como praticamente todos nossos modelos tiverem um bom desempenho vou utilizar o algoritmo de **regressão logística** para ser nosso modelo final. Isso porque diferente dos outros algoritmos que definimos a regressão logística não possui realmente nenhum parâmetro crítico para ajustar. E como nosso conjunto de dados apresentou *outliers* vamos utilizar como padronizador o *RobustScaler()* que apresentou uma boa performance com o algoritmo de regressão logística nos testes realizados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando modelo final\n",
    "Para avaliar nosso modelo vamos utilizar as seguintes métricas:\n",
    "* **Relatório de Classificação (Classification Report)** - Exibe a precisão (*precision*), recuperação (*recall*), pontuação F1 (*f1 score*) e suporte (*support*)\n",
    "    * Precisão : É a capacidade do classificador não rotular uma observação negativa verdadeira como positiva. Mede a **exatidão** dos classificadores\n",
    "    * Recuperação: É a capacidade do classificador de encontrar exemplos positivos. Se quiséssemos ter certeza de encontrar todos os exemplos positivos poderíamos maximizar o recall. Mede a **integridade** dos classificadores\n",
    "    * Pontuação f1: É a média harmônica de precisão e recall. Os valores variam de **0(ruim)** a **1(bom)**\n",
    "    \n",
    "    * Suporte: É o numero de ocorrências de cada classe.\n",
    "* **Cohen Kappa**: precisão da classificação normalizada pelo desequilíbrio das classes nos dados\n",
    "* **ROC AUC Score**: Capacidade de um modelo de discriminar entre classes positivas e negativas. Uma área de 1 representa um modelo que fez todas as previsões perfeitamente. Uma área de 0.5 representa um modelo tão bom quanto aleatório\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões\n",
    "A autenticação das notas de banco é uma tarefa importante. Não é fácil fazer essa detecção de forma manual. A utilização de algoritmos de *machine learning* podem auxiliar estes processos. Neste artigo, mostramos o fluxo de trabalho para um projeto de  *machine learning* que envolve primeiramente entender nosso conjunto de dados, através da análise exploratória dos dados, visualização gráfica a fim de definirmos as melhores abordagens a serem aplicas na construção do modelo final. Para esse projeto em específico nosso modelo de regressão logística teve uma precisão de 98%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "487.99px",
    "width": "568.99px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "818.213px",
    "left": "744px",
    "top": "312.099px",
    "width": "331.916px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "380.881px",
    "left": "1200.83px",
    "right": "20px",
    "top": "83.9851px",
    "width": "589.144px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
